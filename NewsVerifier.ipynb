{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importing the dependencies\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# loading dataset into panda dataframe\n",
        "news_dataset = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# counting the number of missing values in dataset\n",
        "news_dataset.isnull().sum()\n",
        "\n",
        "# replacing null values with empty string\n",
        "news_dataset = news_dataset.fillna('')\n",
        "\n",
        "# merging the author name and news title\n",
        "news_dataset['content'] = news_dataset['author'] + ' ' + news_dataset['title']\n",
        "\n",
        "# separating data and label\n",
        "x = news_dataset.drop(columns='label', axis=1)\n",
        "y = news_dataset['label']\n",
        "\n",
        "# stemming, the process of reducing a word to its Root word\n",
        "port_Stem = PorterStemmer()\n",
        "\n",
        "def stemming(content):\n",
        "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
        "    stemmed_content = stemmed_content.lower()\n",
        "    stemmed_content = stemmed_content.split()\n",
        "    stemmed_content = [port_Stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "    stemmed_content = ' '.join(stemmed_content)\n",
        "    return stemmed_content\n",
        "\n",
        "news_dataset['content'] = news_dataset['content'].apply(stemming)\n",
        "\n",
        "# separating the data & label\n",
        "x = news_dataset['content'].values\n",
        "y = news_dataset['label'].values\n",
        "\n",
        "# converting textual data into numeric data\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x)\n",
        "x = vectorizer.transform(x)\n",
        "\n",
        "# splitting dataset to training and test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)\n",
        "\n",
        "# training the model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# EVALUATION\n",
        "# accuracy score on the training data\n",
        "x_train_prediction = model.predict(x_train)\n",
        "training_data_accuracy = accuracy_score(x_train_prediction, y_train)\n",
        "print('Accuracy score of the training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on the testing data\n",
        "x_test_prediction = model.predict(x_test)\n",
        "testing_data_accuracy = accuracy_score(x_test_prediction, y_test)\n",
        "print('Accuracy score of the testing data: ', testing_data_accuracy)\n",
        "\n",
        "# making a predicting system\n",
        "x_new = x_test[0]\n",
        "prediction = model.predict(x_new)\n",
        "if prediction[0] == 0:\n",
        "    print('The news is real')\n",
        "else:\n",
        "    print('The news is fake')\n",
        "\n",
        "print(y_test[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxqaVNxbtc9T",
        "outputId": "735603dd-f18d-4915-d8c5-8b418fe81111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the training data:  0.9865985576923076\n",
            "Accuracy score of the testing data:  0.9790865384615385\n",
            "The news is fake\n",
            "1\n"
          ]
        }
      ]
    }
  ]
}